from torch import nn


class ConvBlock(nn.Module):
    def __init__(self, in_channels=1, out_channels=1, kernel_size=(3, 3), dilation=1, padding=(1, 1), stride=(1, 1)):
        super(ConvBlock, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,
                      dilation=dilation, padding=padding, stride=stride),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),

        )

    def forward(self, x):
        x = self.conv(x)
        return x


class ConvNet(nn.Module):
    def __init__(self, cfg=None):
        super(ConvNet, self).__init__()
        out_features = 512  # 256
        self.out_features = out_features

        self.layers = nn.ModuleList([
            ConvBlock(in_channels=1, out_channels=32, stride=2),
            nn.MaxPool2d(kernel_size=2, stride=2),
            ConvBlock(in_channels=32, out_channels=64, stride=1),
            nn.MaxPool2d(kernel_size=2, stride=2),
            ConvBlock(in_channels=64, out_channels=64, stride=1),
            nn.MaxPool2d(kernel_size=2, stride=2),
            ConvBlock(in_channels=64, out_channels=64, stride=1),
            nn.MaxPool2d(kernel_size=2, stride=2),
        ])
        self.adapt_layer = nn.AdaptiveMaxPool2d(output_size=(2, 4))

        self.residual_match = nn.ModuleList([
            nn.Sequential(
                nn.Conv2d(1, 32, kernel_size=1, stride=2, padding=0),
                nn.BatchNorm2d(32),
                nn.ReLU(inplace=True),
            ),
            nn.Sequential(
                nn.Conv2d(32, 64, kernel_size=1, stride=1, padding=0),
                nn.BatchNorm2d(64),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(kernel_size=2, stride=2),
            ),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.MaxPool2d(kernel_size=2, stride=2),

            nn.Identity(),
            # nn.Identity(),
        ])

    def forward(self, x):
        for layer in self.layers:
            if x.shape[1] != 64 or isinstance(layer, nn.MaxPool2d):
                _x = 0
            else:
                _x = x  # x
                
            x = layer(x) + _x  # residual
        x = self.adapt_layer(x)  # [25, 64, 7, 7] -> [25, 64, 2, 4]
        x = x.view(x.size(0), -1)
        return x