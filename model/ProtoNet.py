import torch
from torch import nn
import torch.nn.functional as F
from .Fusion import GNNFusion, MLPFusion, TransformerFusion
try:
    from .backbone import get_model
except Exception as e:
    print(e)
    from backbone import get_model


class ProtoNet(nn.Module):
    def __init__(self, cfg):
        super(ProtoNet, self).__init__()
        self.cfg = cfg

        img_backbone_name = cfg.MODEL.IMG_BACKBONE_NAME
        seq_backbone_name = cfg.MODEL.SEQ_BACKBONE_NAME

        self.img_encoder = get_model(img_backbone_name, cfg=cfg)
        self.seq_encoder = get_model(seq_backbone_name, cfg=cfg)
        # self.fuse = self._fusion(mode="concat")  # concat
        # self.fuse = TransformerFusion(cfg)
        self.fuse = GNNFusion(cfg)


        if cfg.CHECKPOINT.NAME:
            name = cfg.CHECKPOINT.NAME
            self.load_state_dict(torch.load(f'./checkpoints/{name}'), strict=False)

        self.loss_fn = nn.CrossEntropyLoss()
        self.data = None

    def forward(self, datas, mode='train'):
        way, shot = self.cfg.TASK.N_WAY, self.cfg.TASK.N_SHOT
        # datas = self.data
        support_img, support_api, query_img, query_api, support_labels, query_labels = \
            (datas['support_img'], datas['support_api'], datas['query_img'], datas['query_api'],
             datas['support_labels'], datas['query_labels'])

        support_img = support_img.squeeze(0)
        support_api = support_api.squeeze(0)
        query_img = query_img.squeeze(0)
        query_api = query_api.squeeze(0)
        support_labels = support_labels.squeeze(0)
        query_labels = query_labels.squeeze(0)

        support_img_encoded = self.img_encoder(support_img)
        query_img_encoded = self.img_encoder(query_img)
        support_api_encoded = self.seq_encoder(support_api)
        query_api_encoded = self.seq_encoder(query_api)

        # Normalize
        support_img_encoded, support_api_encoded, query_img_encoded, query_api_encoded = \
            self.norm(support_img_encoded, support_api_encoded, query_img_encoded, query_api_encoded)

        # fusion
        support_encoded = self.fuse(support_img_encoded, support_api_encoded, mode=mode)
        query_encoded = self.fuse(query_img_encoded, query_api_encoded, mode=mode)


        # Get the logits of image features and API features separately
        img_proto = self.get_proto(support_img_encoded, way, shot, mode='mean').unsqueeze(0)
        img_distances = ((query_img_encoded.unsqueeze(1) - img_proto) ** 2).sum(-1)
        img_logits = -img_distances

        api_proto = self.get_proto(support_api_encoded, way, shot, mode='mean').unsqueeze(0)
        api_distances = ((query_api_encoded.unsqueeze(1) - api_proto) ** 2).sum(-1)
        api_logits = -api_distances


        # Calculate the prototype of each class
        proto = self.get_proto(support_encoded, way, shot, mode='mean').unsqueeze(0)  # mean
        distances = ((query_encoded.unsqueeze(1) - proto) ** 2).sum(-1)

        logits = -distances


        loss = (self.loss_fn(logits, query_labels) * 1
                + self.loss_fn(img_logits, query_labels)
                + self.loss_fn(api_logits, query_labels))

        # loss = self.loss_fn(img_logits, query_labels) + self.loss_fn(api_logits, query_labels)

        # loss = self.loss_fn(api_logits, query_labels)

        outlier = {
            "logits": logits,  # logits + img_logits + api_logits
            "loss": loss,
            "others": {}
        }

        return outlier

    def _fusion(self, mode='concat'):
        if mode == 'concat':
            def f(img_encoded, api_encoded, mode='concat'):
                return torch.cat([img_encoded, api_encoded], dim=1)
            return f

        elif mode == 'add':
            return lambda img_encoded, api_encoded: img_encoded + api_encoded
        elif mode == 'weighted':
            return lambda img_encoded, api_encoded: img_encoded * 0.3 + api_encoded * 0.7
        else:
            raise NotImplementedError

    @staticmethod
    def d(x, y):
        # 计算欧式距离
        n = x.size(0)
        m = y.size(0)
        d = x.size(1)
        x = x.unsqueeze(1).expand(n, m, d)
        y = y.unsqueeze(0).expand(n, m, d)
        dis = torch.pow(x - y, 2)
        return dis.sum(2)

    @staticmethod
    def get_proto(x, way, shot, mode='mean'):
        if mode == 'mean':
            return x.view(way, shot, -1).mean(1)
        elif mode == 'median':
            return torch.median(x.view(way, shot, -1), dim=1).values
        else:
            raise NotImplementedError

    def norm(self, support_img_encoded, support_api_encoded, query_img_encoded, query_api_encoded):
        E_img, D_img = support_img_encoded.mean(dim=0), support_img_encoded.std(dim=0)
        E_api, D_api = support_api_encoded.mean(dim=0), support_api_encoded.std(dim=0)

        support_api_encoded = (support_api_encoded - E_api) / D_api
        query_api_encoded = (query_api_encoded - E_api) / D_api
        support_img_encoded = (support_img_encoded - E_img) / D_img
        query_img_encoded = (query_img_encoded - E_img) / D_img

        return support_img_encoded, support_api_encoded, query_img_encoded, query_api_encoded


if __name__ == '__main__':
    pass