import heapq
import time
from datetime import datetime
import torch
import os
import json


class TrainLogger:
    def __init__(self, cfg):
        self.cfg = cfg
        self.save_dir = self._make_path(cfg)
        self.best_models = []  # A priority queue for storing the best model, the priority is -val_loss
        
        self.max_models = 5
        self.log_file = os.path.join(self.save_dir, 'log.txt')
        self.history_file = os.path.join(self.save_dir, 'history.json')
        self.history = {
            'train_loss': [],
            'val_loss': [],
            'val_acc': [],
        }
        self.test = {}
        self.test_file = os.path.join(self.save_dir, 'test.json')
        self.cfg_file = os.path.join(self.save_dir, 'cfg.json')

    def _make_path(self, cfg):
        base_dir = cfg.LOGGING.BASE_DIR
        dataset_dir = os.path.join(base_dir, cfg.DATASET.NAME)
        model_dir = os.path.join(dataset_dir, cfg.MODEL.NAME)
        task_dir = os.path.join(model_dir, cfg.LOGGING.TASK_NAME)
        # get current time and create folder
        time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
        save_dir = os.path.join(task_dir, time)

        if not os.path.exists(dataset_dir): os.mkdir(dataset_dir)
        if not os.path.exists(model_dir): os.mkdir(model_dir)
        if not os.path.exists(task_dir): os.mkdir(task_dir)
        if not os.path.exists(save_dir): os.mkdir(save_dir)

        return save_dir

    def update(self, model, statistics):
        train_loss, val_loss, val_accuracy = statistics['train_loss'], statistics['val_loss'], statistics['val_acc']

        self.history['train_loss'].append(train_loss)
        self.history['val_loss'].append(val_loss)
        self.history['val_acc'].append(val_accuracy)

        # Check and update the best model
        self._update_best_models(model, statistics)

    def _update_best_models(self, model, statistics):
        max_models = self.max_models
        val_accuracy, val_loss, epoch = statistics['val_acc'], statistics['val_loss'], statistics['epoch']
        if len(self.best_models) < max_models or val_loss > self.best_models[0][0]:
            model_path = os.path.join(self.save_dir, f'model_{val_accuracy}.pt')
            torch.save(model.state_dict(), model_path)

            if len(self.best_models) == max_models:
                _, _, worst_model_path, _ = heapq.heappop(self.best_models)
                if os.path.exists(worst_model_path):
                    os.remove(worst_model_path)
            time.sleep(0.01)
            heapq.heappush(self.best_models, (-val_loss, val_accuracy, model_path, epoch))
            torch.save(model.state_dict(), model_path)

    def get_history(self):
        return self.history

    def _log_history(self, train_loss, val_loss, val_accuracy):
        with open(self.log_file, 'a') as file:
            file.write(f'train_loss: {train_loss}, val_loss: {val_loss}, '
                       f'val_acc: {val_accuracy}\n')

    def _log_test(self):
        with open(self.test_file, 'w') as file:
            json.dump(self.test, file, indent=4)

    def _save_history(self):
        with open(self.history_file, 'w') as file:
            json.dump(self.history, file, indent=4)

    def _save_cfg(self):
        with open(self.cfg_file, 'w') as file:
            json.dump(self.cfg, file, indent=4)

    def save(self):
        print(f"save to {self.save_dir}")
        self._log_test()
        self._save_history()
        self._save_cfg()

    def show_info(self, statistics: dict):
        print(statistics)
        # for k in statistics.keys():
        #     print(f"{k}: {statistics[k]}", end=',')
