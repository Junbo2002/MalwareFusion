import math

import torch
from torch.optim.lr_scheduler import StepLR

from utils import load_cfg, setup, TrainLogger
from dataset import build_dataloader
from model import get_model
from tqdm import tqdm


cfg = load_cfg()
# print(cfg)
setup(cfg)
logger = TrainLogger(cfg)
EPOCH = cfg.TRAIN.EPOCH
VAL_PER_EPOCH = cfg.TRAIN.VAL_PER_EPOCH
TEST_TASK = cfg.TRAIN.TEST_TASK

train_dataloader, val_dataloader, test_dataloader = (
    build_dataloader(cfg))

model = get_model(cfg).cuda()

optimizer = getattr(torch.optim, cfg.SOLVER.OPTIMIZER)(
    model.parameters(), lr=cfg.SOLVER.BASE_LR, weight_decay=1e-2)  # cfg.SOLVER.WEIGHT_DECAY
scheduler = StepLR(optimizer, step_size=10000, gamma=1)  # cfg.SOLVER.SCHEDULER_GAMMA

# Number of batches to accumulate
accumulation_steps = 1

train_loss, val_loss, train_acc = 0., 0., 0.
cfg.LOGGING.VERBOSE = True

print('===========TRAIN=============')
for epoch in tqdm(range(EPOCH)):
    model.train()
    for datas in train_dataloader:
        # support, support_labels, query, query_labels, clean_idx
        outlier = model(datas, mode='train')  # [150, 10] query_labels [1, 150]
        loss = outlier["loss"]
        optimizer.zero_grad()
        loss.backward()
        train_loss += loss.item()
        optimizer.step()
        
        is_true = (outlier["logits"].argmax(dim=1) == datas["query_labels"])
        train_acc += is_true.float().mean().item()


    if (epoch + 1) % VAL_PER_EPOCH == 0:
        if cfg.LOGGING.VERBOSE:
            print(f"train_acc: {100 * train_acc / VAL_PER_EPOCH:.2f}%")

        model.eval()
        with torch.no_grad():
            val_acc, tasks = 0., cfg.TRAIN.VAL_TASK
            val_f1 = 0.
            others = {}

            for i in range(tasks):
                for datas in val_dataloader:
                    query_labels = datas["query_labels"]
                    outlier = model(datas, mode='val')
                    query_pred = outlier["logits"]
                    if "loss" in outlier: val_loss += outlier["loss"].item()
                    pred = query_pred.argmax(dim=1)
                    labels = query_labels.squeeze(0)
                    acc = (pred == labels).float().mean().item()
                    val_acc += acc

            statistic = {
                "val_acc": f"{100 * val_acc / tasks:.2f}",
                "val_F1": f"{100 * val_f1 / tasks:.2f}",
                "val_loss": val_loss / tasks,
                "train_loss": train_loss / VAL_PER_EPOCH,
                "epoch": epoch + 1,
            }

            logger.update(model, statistic)
            if cfg.LOGGING.VERBOSE:
                logger.show_info(statistic)

        train_loss, val_loss = 0., 0.
        train_acc = 0.

        scheduler.step()


setup(cfg)
# TEST
best_models = logger.best_models
best_models.sort(reverse=True)

model.eval()
print('===========TEST=============')
ACCs = []
with torch.no_grad():
    for val_loss, val_acc, model_path, epoch in best_models:
        try:
            model.load_state_dict(torch.load(model_path))
        except:
            print(f"load {model_path} failed")
            continue
        test_acc = 0.
        test_f1 = 0.
        for i in tqdm(range(TEST_TASK)):
            for datas in test_dataloader:
                outlier = model(datas, mode='test')
                query_labels = datas["query_labels"]
                query_pred = outlier["logits"]
                pred = query_pred.argmax(dim=1).cpu()
                labels = query_labels.squeeze(0).cpu()
                acc = (pred == labels).float().mean().item()
                test_acc += acc

        statistic = {
            "test_acc": f"{100 * test_acc / TEST_TASK:.2f}",
            "test_F1": f"{100 * test_f1 / TEST_TASK:.2f}",
            "val_loss": abs(val_loss),
        }
        statistic.update(others)
        logger.test[model_path] = test_acc
        print(f"{model_path.split('/')[-1]} At {epoch} epoch: {statistic}")
        ACCs.append(test_acc / TEST_TASK)

        confidences = []  # 0.95 interval
        sample_nums = 25
        for _ in range(20):
            for i in range(sample_nums):
                for datas in test_dataloader:
                    outlier = model(datas, mode='test')
                    query_labels = datas["query_labels"]
                    query_pred = outlier["logits"]
                    pred = query_pred.argmax(dim=1).cpu()
                    labels = query_labels.squeeze(0).cpu()
                    acc = (pred == labels).float().mean().item()
                    confidence = 1.96 * math.sqrt(acc * (1 - acc) / sample_nums)
                    confidences.append(confidence)
        print("confidences:", sum(confidences) / len(confidences))

logger.save()
print(f'task: {cfg.TASK.N_WAY}-way-{cfg.TASK.N_SHOT}-shot')
if ACCs:
    print(f'best test ACC: {max(ACCs)}')
    print(f"mean test ACC: {sum(ACCs) / len(ACCs)}")
    print(f"{100 * max(ACCs):.2f}/{100 * sum(ACCs) / len(ACCs):.2f}")


# pretrained
test_acc = 0.
with torch.no_grad():
    for i in tqdm(range(TEST_TASK)):
        for datas in test_dataloader:
            outlier = model(datas, mode='test')
            query_labels = datas["query_labels"].squeeze(0).cuda()
            query_pred = outlier["logits"]
            pred = query_pred.argmax(dim=1)

            acc = (pred == query_labels).float().mean()

            test_acc += acc.item()

    test_acc = test_acc / TEST_TASK
    print(f"final model ACC: {test_acc}")